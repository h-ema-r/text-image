{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yiTtqihn5NEj"
      },
      "outputs": [],
      "source": [
        "!pip install torch torchvision torchaudio -f https://download.pytorch.org/whl/torch_stable.html\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate\n"
      ],
      "metadata": {
        "id": "AzSYepqe9FHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "ByUvIH5L6MuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install diffusers"
      ],
      "metadata": {
        "id": "ocSZz-lW6ZWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "id": "kowPl0ju9Nb1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.tools.base import Tool, get_default_device\n",
        "from transformers.utils import is_accelerate_available\n",
        "import torch\n",
        "\n",
        "from diffusers import DiffusionPipeline, DPMSolverMultistepScheduler"
      ],
      "metadata": {
        "id": "f1aOA9gm5lUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TEXT_TO_IMAGE_DESCRIPTION = (\n",
        "    \"This is a tool that creates an image according to a prompt, which is a text description. It takes an input named `prompt` which \"\n",
        "    \"contains the image description and outputs an image.\"\n",
        ")"
      ],
      "metadata": {
        "id": "sZvojWMF5lWK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextToImageTool(Tool):\n",
        "    default_checkpoint = \"runwayml/stable-diffusion-v1-5\"\n",
        "    description = TEXT_TO_IMAGE_DESCRIPTION\n",
        "    inputs = ['text']\n",
        "    outputs = ['image']\n",
        "\n",
        "    def __init__(self, device=None, **hub_kwargs) -> None:\n",
        "        if not is_accelerate_available():\n",
        "            raise ImportError(\"Accelerate should be installed in order to use tools.\")\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.device = device\n",
        "        self.pipeline = None\n",
        "        self.hub_kwargs = hub_kwargs\n",
        "\n",
        "    def setup(self):\n",
        "        if self.device is None:\n",
        "            self.device = get_default_device()\n",
        "\n",
        "        self.pipeline = DiffusionPipeline.from_pretrained(self.default_checkpoint)\n",
        "        self.pipeline.scheduler = DPMSolverMultistepScheduler.from_config(self.pipeline.scheduler.config)\n",
        "        self.pipeline.to(self.device)\n",
        "\n",
        "        if self.device.type == \"cuda\":\n",
        "            self.pipeline.to(torch_dtype=torch.float16)\n",
        "\n",
        "        self.is_initialized = True\n",
        "\n",
        "    def __call__(self, prompt):\n",
        "        if not self.is_initialized:\n",
        "            self.setup()\n",
        "\n",
        "        negative_prompt = \"low quality, bad quality, deformed, low resolution\"\n",
        "        added_prompt = \" , highest quality, highly realistic, very high resolution\"\n",
        "\n",
        "        return self.pipeline(prompt + added_prompt, negative_prompt=negative_prompt, num_inference_steps=25).images[0]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zlOwBmlE5lYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import gradio as gr\n",
        "\n",
        "tool = TextToImageTool()\n",
        "\n",
        "def fn(*args, **kwargs):\n",
        "    return tool(*args, **kwargs)\n",
        "\n",
        "gr.Interface(\n",
        "    fn=fn,\n",
        "    inputs=tool.inputs,\n",
        "    outputs=tool.outputs,\n",
        "    title=\"TextToImageTool\",\n",
        "    article=tool.description,\n",
        ").queue(concurrency_count=5).launch(share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "id": "-ut7oEUM5lgR",
        "outputId": "2b6d2308-c3e2-4275-c3b3-7eee42b072ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://fa3d435ce45973edbd.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://fa3d435ce45973edbd.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ]
}